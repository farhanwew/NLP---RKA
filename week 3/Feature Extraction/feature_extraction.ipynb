{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\farha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>remove_slang</th>\n",
       "      <th>remove_elongation</th>\n",
       "      <th>emoji_to_text</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>stem</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>remove_stop_words_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@likromiahooy Paginya ppn naik 12%</td>\n",
       "      <td>@likromiahooy paginya ppn naik 12</td>\n",
       "      <td>@likromiahooy paginya ppn naik 12</td>\n",
       "      <td>@likromiahooy paginya ppn naik 12</td>\n",
       "      <td>@likromiahooy paginya ppn naik 12</td>\n",
       "      <td>['paginya', 'ppn', 'naik', '12']</td>\n",
       "      <td>['pagi', 'ppn', 'naik', '12']</td>\n",
       "      <td>['pagi', 'ppn', '12']</td>\n",
       "      <td>['pagi', 'ppn', '12']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AdamVelcro 1. Krn sudah dikondisikan di media...</td>\n",
       "      <td>@adamvelcro 1 krn sudah dikondisikan di media ...</td>\n",
       "      <td>@adamvelcro 1 karena sudah dikondisikan di med...</td>\n",
       "      <td>@adamvelcro 1 karena sudah dikondisikan di med...</td>\n",
       "      <td>@adamvelcro 1 karena sudah dikondisikan di med...</td>\n",
       "      <td>['1', 'karena', 'sudah', 'dikondisikan', 'di',...</td>\n",
       "      <td>['1', 'karena', 'sudah', 'kondisi', 'di', 'med...</td>\n",
       "      <td>['1', 'kondisi', 'media', 'kenaikan', 'ppn', '...</td>\n",
       "      <td>['1', 'kondisi', 'media', 'kenaikan', 'ppn', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@exhumaclown rapat ppn krn naik jadi 12% kah?</td>\n",
       "      <td>@exhumaclown rapat ppn krn naik jadi 12 kah</td>\n",
       "      <td>@exhumaclown rapat ppn karena naik jadi 12 kah</td>\n",
       "      <td>@exhumaclown rapat ppn karena naik jadi 12 kah</td>\n",
       "      <td>@exhumaclown rapat ppn karena naik jadi 12 kah</td>\n",
       "      <td>['rapat', 'ppn', 'karena', 'naik', 'jadi', '12...</td>\n",
       "      <td>['rapat', 'ppn', 'karena', 'naik', 'jadi', '12...</td>\n",
       "      <td>['rapat', 'ppn', '12', 'kah']</td>\n",
       "      <td>['rapat', 'ppn', '12']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apakah ini hari pemborosan sebelum ppn naik 12%?</td>\n",
       "      <td>apakah ini hari pemborosan sebelum ppn naik 12</td>\n",
       "      <td>apakah ini hari pemborosan sebelum ppn naik 12</td>\n",
       "      <td>apakah ini hari pemborosan sebelum ppn naik 12</td>\n",
       "      <td>apakah ini hari pemborosan sebelum ppn naik 12</td>\n",
       "      <td>['apakah', 'ini', 'hari', 'pemborosan', 'sebel...</td>\n",
       "      <td>['apakah', 'ini', 'hari', 'boros', 'belum', 'p...</td>\n",
       "      <td>['boros', 'ppn', '12']</td>\n",
       "      <td>['boros', 'ppn', '12']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kompascom Kl pabrik / usaha nya yg memproduks...</td>\n",
       "      <td>@kompascom kl pabrik  usaha nya yg memproduksi...</td>\n",
       "      <td>@kompascom kalo pabrik  usaha nya yang memprod...</td>\n",
       "      <td>@kompascom kalo pabrik  usaha nya yang memprod...</td>\n",
       "      <td>@kompascom kalo pabrik  usaha nya yang memprod...</td>\n",
       "      <td>['kalo', 'pabrik', 'usaha', 'nya', 'yang', 'me...</td>\n",
       "      <td>['kalau', 'pabrik', 'usaha', 'nya', 'yang', 'm...</td>\n",
       "      <td>['pabrik', 'usaha', 'nya', 'memproduksi', 'pro...</td>\n",
       "      <td>['pabrik', 'usaha', 'memproduksi', 'produk', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0                 @likromiahooy Paginya ppn naik 12%   \n",
       "1  @AdamVelcro 1. Krn sudah dikondisikan di media...   \n",
       "2      @exhumaclown rapat ppn krn naik jadi 12% kah?   \n",
       "3  Apakah ini hari pemborosan sebelum ppn naik 12%?    \n",
       "4  @kompascom Kl pabrik / usaha nya yg memproduks...   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0                  @likromiahooy paginya ppn naik 12   \n",
       "1  @adamvelcro 1 krn sudah dikondisikan di media ...   \n",
       "2        @exhumaclown rapat ppn krn naik jadi 12 kah   \n",
       "3    apakah ini hari pemborosan sebelum ppn naik 12    \n",
       "4  @kompascom kl pabrik  usaha nya yg memproduksi...   \n",
       "\n",
       "                                        remove_slang  \\\n",
       "0                  @likromiahooy paginya ppn naik 12   \n",
       "1  @adamvelcro 1 karena sudah dikondisikan di med...   \n",
       "2     @exhumaclown rapat ppn karena naik jadi 12 kah   \n",
       "3    apakah ini hari pemborosan sebelum ppn naik 12    \n",
       "4  @kompascom kalo pabrik  usaha nya yang memprod...   \n",
       "\n",
       "                                   remove_elongation  \\\n",
       "0                  @likromiahooy paginya ppn naik 12   \n",
       "1  @adamvelcro 1 karena sudah dikondisikan di med...   \n",
       "2     @exhumaclown rapat ppn karena naik jadi 12 kah   \n",
       "3    apakah ini hari pemborosan sebelum ppn naik 12    \n",
       "4  @kompascom kalo pabrik  usaha nya yang memprod...   \n",
       "\n",
       "                                       emoji_to_text  \\\n",
       "0                  @likromiahooy paginya ppn naik 12   \n",
       "1  @adamvelcro 1 karena sudah dikondisikan di med...   \n",
       "2     @exhumaclown rapat ppn karena naik jadi 12 kah   \n",
       "3    apakah ini hari pemborosan sebelum ppn naik 12    \n",
       "4  @kompascom kalo pabrik  usaha nya yang memprod...   \n",
       "\n",
       "                                        tweet_tokens  \\\n",
       "0                   ['paginya', 'ppn', 'naik', '12']   \n",
       "1  ['1', 'karena', 'sudah', 'dikondisikan', 'di',...   \n",
       "2  ['rapat', 'ppn', 'karena', 'naik', 'jadi', '12...   \n",
       "3  ['apakah', 'ini', 'hari', 'pemborosan', 'sebel...   \n",
       "4  ['kalo', 'pabrik', 'usaha', 'nya', 'yang', 'me...   \n",
       "\n",
       "                                                stem  \\\n",
       "0                      ['pagi', 'ppn', 'naik', '12']   \n",
       "1  ['1', 'karena', 'sudah', 'kondisi', 'di', 'med...   \n",
       "2  ['rapat', 'ppn', 'karena', 'naik', 'jadi', '12...   \n",
       "3  ['apakah', 'ini', 'hari', 'boros', 'belum', 'p...   \n",
       "4  ['kalau', 'pabrik', 'usaha', 'nya', 'yang', 'm...   \n",
       "\n",
       "                                    remove_stopwords  \\\n",
       "0                              ['pagi', 'ppn', '12']   \n",
       "1  ['1', 'kondisi', 'media', 'kenaikan', 'ppn', '...   \n",
       "2                      ['rapat', 'ppn', '12', 'kah']   \n",
       "3                             ['boros', 'ppn', '12']   \n",
       "4  ['pabrik', 'usaha', 'nya', 'memproduksi', 'pro...   \n",
       "\n",
       "                              remove_stop_words_nltk  \n",
       "0                              ['pagi', 'ppn', '12']  \n",
       "1  ['1', 'kondisi', 'media', 'kenaikan', 'ppn', '...  \n",
       "2                             ['rapat', 'ppn', '12']  \n",
       "3                             ['boros', 'ppn', '12']  \n",
       "4  ['pabrik', 'usaha', 'memproduksi', 'produk', '...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/PPN_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remove_stop_words_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['pagi', 'ppn', '12']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['1', 'kondisi', 'media', 'kenaikan', 'ppn', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['rapat', 'ppn', '12']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['boros', 'ppn', '12']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['pabrik', 'usaha', 'memproduksi', 'produk', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>['pasrah', 'nrimo', 'ing', 'pandum', 'nek', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>['bilang', 'ppn', '12', 'sasar', 'barang', 'me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>['ppn', '12', 'tanda', 'kenaikan', 'duit', '12']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>['ppn', '12', 'duit', 'negara', 'masyarakat', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>['voters', '02', 'gigit', 'batu', 'pilih', 'bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                remove_stop_words_nltk\n",
       "0                                ['pagi', 'ppn', '12']\n",
       "1    ['1', 'kondisi', 'media', 'kenaikan', 'ppn', '...\n",
       "2                               ['rapat', 'ppn', '12']\n",
       "3                               ['boros', 'ppn', '12']\n",
       "4    ['pabrik', 'usaha', 'memproduksi', 'produk', '...\n",
       "..                                                 ...\n",
       "306  ['pasrah', 'nrimo', 'ing', 'pandum', 'nek', 'p...\n",
       "307  ['bilang', 'ppn', '12', 'sasar', 'barang', 'me...\n",
       "308   ['ppn', '12', 'tanda', 'kenaikan', 'duit', '12']\n",
       "309  ['ppn', '12', 'duit', 'negara', 'masyarakat', ...\n",
       "310  ['voters', '02', 'gigit', 'batu', 'pilih', 'bi...\n",
       "\n",
       "[311 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus  = df[['remove_stop_words_nltk']].copy()\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remove_stop_words_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pagi, ppn, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, kondisi, media, kenaikan, ppn, 12, inisias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rapat, ppn, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[boros, ppn, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[pabrik, usaha, memproduksi, produk, pangan, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>[pasrah, nrimo, ing, pandum, nek, ppn, 12, hore]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>[bilang, ppn, 12, sasar, barang, mewah, doang,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>[ppn, 12, tanda, kenaikan, duit, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>[ppn, 12, duit, negara, masyarakat, potong, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>[voters, 02, gigit, batu, pilih, bikin, ppn, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                remove_stop_words_nltk\n",
       "0                                      [pagi, ppn, 12]\n",
       "1    [1, kondisi, media, kenaikan, ppn, 12, inisias...\n",
       "2                                     [rapat, ppn, 12]\n",
       "3                                     [boros, ppn, 12]\n",
       "4    [pabrik, usaha, memproduksi, produk, pangan, k...\n",
       "..                                                 ...\n",
       "306   [pasrah, nrimo, ing, pandum, nek, ppn, 12, hore]\n",
       "307  [bilang, ppn, 12, sasar, barang, mewah, doang,...\n",
       "308               [ppn, 12, tanda, kenaikan, duit, 12]\n",
       "309  [ppn, 12, duit, negara, masyarakat, potong, pr...\n",
       "310  [voters, 02, gigit, batu, pilih, bikin, ppn, 1...\n",
       "\n",
       "[311 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['remove_stop_words_nltk'] = corpus['remove_stop_words_nltk'].apply(lambda x: ast.literal_eval(x))\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remove_stop_words_nltk</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pagi, ppn, 12]</td>\n",
       "      <td>pagi ppn 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, kondisi, media, kenaikan, ppn, 12, inisias...</td>\n",
       "      <td>1 kondisi media kenaikan ppn 12 inisiasi pdip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rapat, ppn, 12]</td>\n",
       "      <td>rapat ppn 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[boros, ppn, 12]</td>\n",
       "      <td>boros ppn 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[pabrik, usaha, memproduksi, produk, pangan, k...</td>\n",
       "      <td>pabrik usaha memproduksi produk pangan kena pp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>[pasrah, nrimo, ing, pandum, nek, ppn, 12, hore]</td>\n",
       "      <td>pasrah nrimo ing pandum nek ppn 12 hore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>[bilang, ppn, 12, sasar, barang, mewah, doang,...</td>\n",
       "      <td>bilang ppn 12 sasar barang mewah doang baca ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>[ppn, 12, tanda, kenaikan, duit, 12]</td>\n",
       "      <td>ppn 12 tanda kenaikan duit 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>[ppn, 12, duit, negara, masyarakat, potong, pr...</td>\n",
       "      <td>ppn 12 duit negara masyarakat potong program a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>[voters, 02, gigit, batu, pilih, bikin, ppn, 1...</td>\n",
       "      <td>voters 02 gigit batu pilih bikin ppn 12 makan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                remove_stop_words_nltk  \\\n",
       "0                                      [pagi, ppn, 12]   \n",
       "1    [1, kondisi, media, kenaikan, ppn, 12, inisias...   \n",
       "2                                     [rapat, ppn, 12]   \n",
       "3                                     [boros, ppn, 12]   \n",
       "4    [pabrik, usaha, memproduksi, produk, pangan, k...   \n",
       "..                                                 ...   \n",
       "306   [pasrah, nrimo, ing, pandum, nek, ppn, 12, hore]   \n",
       "307  [bilang, ppn, 12, sasar, barang, mewah, doang,...   \n",
       "308               [ppn, 12, tanda, kenaikan, duit, 12]   \n",
       "309  [ppn, 12, duit, negara, masyarakat, potong, pr...   \n",
       "310  [voters, 02, gigit, batu, pilih, bikin, ppn, 1...   \n",
       "\n",
       "                                                string  \n",
       "0                                          pagi ppn 12  \n",
       "1    1 kondisi media kenaikan ppn 12 inisiasi pdip ...  \n",
       "2                                         rapat ppn 12  \n",
       "3                                         boros ppn 12  \n",
       "4    pabrik usaha memproduksi produk pangan kena pp...  \n",
       "..                                                 ...  \n",
       "306            pasrah nrimo ing pandum nek ppn 12 hore  \n",
       "307  bilang ppn 12 sasar barang mewah doang baca ha...  \n",
       "308                      ppn 12 tanda kenaikan duit 12  \n",
       "309  ppn 12 duit negara masyarakat potong program a...  \n",
       "310  voters 02 gigit batu pilih bikin ppn 12 makan ...  \n",
       "\n",
       "[311 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['string'] = corpus['remove_stop_words_nltk'].apply(lambda x: ' '.join(x))\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW)\n",
    "\n",
    "A Bag of words is a an approach to transform text into numerical representation\n",
    "\n",
    "- Describes the occurrence of words within a document or a collection of documents (corpus)\n",
    "- Builds a vocabulary of the words and a measure of their presence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>011</th>\n",
       "      <th>012</th>\n",
       "      <th>02</th>\n",
       "      <th>021</th>\n",
       "      <th>022</th>\n",
       "      <th>03</th>\n",
       "      <th>08133099932</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>xmgh</th>\n",
       "      <th>yaelah</th>\n",
       "      <th>yalon</th>\n",
       "      <th>yaudahlah</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zaman</th>\n",
       "      <th>zonk</th>\n",
       "      <th>zulhas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 1412 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     011  012  02  021  022  03  08133099932  10  100  1000  ...  xmgh  \\\n",
       "0      0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "1      0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "2      0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "3      0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "4      0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "..   ...  ...  ..  ...  ...  ..          ...  ..  ...   ...  ...   ...   \n",
       "306    0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "307    0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "308    0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "309    0    0   0    0    0   0            0   0    0     0  ...     0   \n",
       "310    0    0   1    0    0   0            0   0    0     0  ...     0   \n",
       "\n",
       "     yaelah  yalon  yaudahlah  yes  you  yourself  zaman  zonk  zulhas  \n",
       "0         0      0          0    0    0         0      0     0       0  \n",
       "1         0      0          0    0    0         0      0     0       0  \n",
       "2         0      0          0    0    0         0      0     0       0  \n",
       "3         0      0          0    0    0         0      0     0       0  \n",
       "4         0      0          0    0    0         0      0     0       0  \n",
       "..      ...    ...        ...  ...  ...       ...    ...   ...     ...  \n",
       "306       0      0          0    0    0         0      0     0       0  \n",
       "307       0      0          0    0    0         0      0     0       0  \n",
       "308       0      0          0    0    0         0      0     0       0  \n",
       "309       0      0          0    0    0         0      0     0       0  \n",
       "310       0      0          0    0    0         0      0     1       0  \n",
       "\n",
       "[311 rows x 1412 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(corpus[''])\n",
    "pd.DataFrame(X_bow.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency - Inverse Document Frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m vectorizer_tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m----> 2\u001b[0m X_tfidf \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer_tfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mremove_stop_words_nltk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_tfidf\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mvectorizer_tfidf\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n",
      "File \u001b[1;32mc:\\Users\\farha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\farha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\farha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\farha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform()\n",
    "pd.DataFrame(X_tfidf.toarray(), columns=vectorizer_tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
